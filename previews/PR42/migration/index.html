<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>...migrate from BenchmarkTools · Chairmarks.jl</title><meta name="title" content="...migrate from BenchmarkTools · Chairmarks.jl"/><meta property="og:title" content="...migrate from BenchmarkTools · Chairmarks.jl"/><meta property="twitter:title" content="...migrate from BenchmarkTools · Chairmarks.jl"/><meta name="description" content="Documentation for Chairmarks.jl."/><meta property="og:description" content="Documentation for Chairmarks.jl."/><meta property="twitter:description" content="Documentation for Chairmarks.jl."/><meta property="og:url" content="https://Chairmarks.lilithhafner.com/migration/"/><meta property="twitter:url" content="https://Chairmarks.lilithhafner.com/migration/"/><link rel="canonical" href="https://Chairmarks.lilithhafner.com/migration/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">Chairmarks.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../why/">Why use Chairmarks?</a></li><li><a class="tocitem" href="../tutorial/">Tutorial</a></li><li><span class="tocitem">How To</span><ul><li class="is-active"><a class="tocitem" href>...migrate from BenchmarkTools</a></li><li><a class="tocitem" href="../autoload/">...install Charimarks ergonomically</a></li><li><a class="tocitem" href="../regressions/">...perform automated regression testing on a package</a></li></ul></li><li><a class="tocitem" href="../reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">How To</a></li><li class="is-active"><a href>...migrate from BenchmarkTools</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>...migrate from BenchmarkTools</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/LilithHafner/Chairmarks.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/LilithHafner/Chairmarks.jl/blob/main/docs/src/migration.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="migration"><a class="docs-heading-anchor" href="#migration">How to migrate from BenchmarkTools to Chairmarks</a><a id="migration-1"></a><a class="docs-heading-anchor-permalink" href="#migration" title="Permalink"></a></h1><p>Chairmarks has a similar samples/evals model to BenchmarkTools. It preserves the keyword arguments <code>samples</code>, <code>evals</code>, and <code>seconds</code>. Unlike BenchmarkTools, the <code>seconds</code> argument is honored even as it drops down to the order of 30μs (<code>@b @b hash(rand()) seconds=.00003</code>). While accuracy does decay as the total number of evaluations and samples decreases, it remains quite reasonable (e.g. I see a noise of about 30% when benchmarking <code>@b hash(rand()) seconds=.00003</code>). This makes it much more reasonable to perform meta-analysis such as computing the time it takes to hash a thousand different lengthed arrays with <code>[@b hash(rand(n)) seconds=.001 for n in 1:1000]</code>.</p><p>Both BenchmarkTools and Chairmarks use an evaluation model structured like this:</p><pre><code class="language-julia hljs">init()
samples = []
for _ in 1:samples
    setup()
    t0 = time()
    for _ in 1:evals
        f()
    end
    t1 = time()
    push!(samples, t1 - t0)
    teardown()
end
return samples</code></pre><p>In BenchmarkTools, you specify <code>f</code> and <code>setup</code> with the invocation <code>@benchmark f setup=(setup)</code>. In Chairmarks, you specify <code>f</code> and <code>setup</code> with the invocation <code>@be setup f</code>. In BenchmarkTools, <code>setup</code> and <code>f</code> communicate via shared local variables in code generated by BenchmarkTools. In Chairmarks, the function <code>f</code> is passed the return value of the function <code>setup</code> as an argument. Chairmarks also lets you specify <code>teardown</code>, which is not possible with BenchmarkTools, and an <code>init</code> which can be emulated with interpolation using BenchmarkTools.</p><p>Here are some examples of corresponding invocations in BenchmarkTools and Chairmarks:</p><table><tr><th style="text-align: right">BenchmarkTools</th><th style="text-align: right">Charimarks</th></tr><tr><td style="text-align: right"><code>@btime rand();</code></td><td style="text-align: right"><code>@b rand()</code></td></tr><tr><td style="text-align: right"><code>@btime sort!(x) setup=(x=rand(100)) evals=1;</code></td><td style="text-align: right"><code>@b rand(100) sort! evals=1</code></td></tr><tr><td style="text-align: right"><code>@btime sort!(x, rev=true) setup=(x=rand(100)) evals=1;</code></td><td style="text-align: right"><code>@b rand(100) sort!(_, rev=true) evals=1</code></td></tr><tr><td style="text-align: right"><code>@btime issorted(sort!(x)) || error() setup=(x=rand(100)) evals=1</code></td><td style="text-align: right"><code>@b rand(100) sort! issorted(_) || error() evals=1</code></td></tr><tr><td style="text-align: right"><code>let X = rand(100); @btime issorted(sort!($X)) || error() setup=(rand!($X)) evals=1 end</code></td><td style="text-align: right"><code>@b rand(100) rand! sort! issorted(_) || error() evals=1</code></td></tr></table><p>For automated regression tests, <a href="https://github.com/LilithHafner/RegressionTests.jl">RegressionTests.jl</a> is a work in progress replacement for the <code>BenchmarkGroup</code> and <code>@benchmarkable</code> system. Because Chairmarks is efficiently and stably autotuned and RegressionTests.jl is inherently robust to noise, there is no need for parameter caching.</p><h3 id="Toplevel-API"><a class="docs-heading-anchor" href="#Toplevel-API">Toplevel API</a><a id="Toplevel-API-1"></a><a class="docs-heading-anchor-permalink" href="#Toplevel-API" title="Permalink"></a></h3><p>Chairmarks always returns the benchmark result, while BenchmarkTools mirrors the more diverse base API.</p><table><tr><th style="text-align: right">BenchmarkTools</th><th style="text-align: right">Chairmarks</th><th style="text-align: right">Base</th></tr><tr><td style="text-align: right"><code>minimum(@benchmark _)</code></td><td style="text-align: right"><code>@b</code></td><td style="text-align: right">N/A</td></tr><tr><td style="text-align: right"><code>@benchmark</code></td><td style="text-align: right"><code>@be</code></td><td style="text-align: right">N/A</td></tr><tr><td style="text-align: right"><code>@belapsed</code></td><td style="text-align: right"><code>(@b _).time</code></td><td style="text-align: right"><code>@elapsed</code></td></tr><tr><td style="text-align: right"><code>@btime</code></td><td style="text-align: right"><code>display(@b _); _</code></td><td style="text-align: right"><code>@time</code></td></tr><tr><td style="text-align: right">N/A</td><td style="text-align: right"><code>(@b _).allocs</code></td><td style="text-align: right"><code>@allocations</code></td></tr><tr><td style="text-align: right"><code>@ballocated</code></td><td style="text-align: right"><code>(@b _).bytes</code></td><td style="text-align: right"><code>@allocated</code></td></tr></table><p>Chairmarks may provide <code>@belapsed</code>, <code>@btime</code>, <code>@ballocated</code>, and <code>@ballocations</code> in the future.</p><h3 id="Fields"><a class="docs-heading-anchor" href="#Fields">Fields</a><a id="Fields-1"></a><a class="docs-heading-anchor-permalink" href="#Fields" title="Permalink"></a></h3><p>Benchmark results have the following fields:</p><table><tr><th style="text-align: right">Chairmarks</th><th style="text-align: right">BenchmarkTools</th><th style="text-align: right">Description</th></tr><tr><td style="text-align: right"><code>x.time</code></td><td style="text-align: right"><code>x.time*1e9</code></td><td style="text-align: right">Runtime in seconds</td></tr><tr><td style="text-align: right"><code>x.time/1e9</code></td><td style="text-align: right"><code>x.time</code></td><td style="text-align: right">Runtime in nanoseconds</td></tr><tr><td style="text-align: right"><code>x.allocs</code></td><td style="text-align: right"><code>x.allocs</code></td><td style="text-align: right">Number of allocations</td></tr><tr><td style="text-align: right"><code>x.bytes</code></td><td style="text-align: right"><code>x.memory</code></td><td style="text-align: right">Number of bytes allocated across all allocations</td></tr><tr><td style="text-align: right"><code>x.gc_fraction</code></td><td style="text-align: right"><code>x.gctime / x.time</code></td><td style="text-align: right">Fraction of time spent in garbage collection</td></tr><tr><td style="text-align: right"><code>x.gc_time*x.time</code></td><td style="text-align: right"><code>x.gctime</code></td><td style="text-align: right">Time spent in garbage collection</td></tr><tr><td style="text-align: right"><code>x.compile_fraction</code></td><td style="text-align: right">N/A</td><td style="text-align: right">Fraction of time spent compiling</td></tr><tr><td style="text-align: right"><code>x.recompile_fraction</code></td><td style="text-align: right">N/A</td><td style="text-align: right">Fraction of time spent compiling which was on recompilation</td></tr><tr><td style="text-align: right"><code>x.warmup</code></td><td style="text-align: right"><code>true</code></td><td style="text-align: right">weather or not the sample had a warmup run before it</td></tr><tr><td style="text-align: right"><code>x.checksum</code></td><td style="text-align: right">N/A</td><td style="text-align: right">a checksum computed from the return values of the benchmarked code</td></tr><tr><td style="text-align: right"><code>x.evals</code></td><td style="text-align: right"><code>x.params.evals</code></td><td style="text-align: right">the number of evaluations in the sample</td></tr></table><p>Note that these fields are likely to change in Chairmarks 1.0.</p><h3 id="Nonconstant-globals-and-interpolation"><a class="docs-heading-anchor" href="#Nonconstant-globals-and-interpolation">Nonconstant globals and interpolation</a><a id="Nonconstant-globals-and-interpolation-1"></a><a class="docs-heading-anchor-permalink" href="#Nonconstant-globals-and-interpolation" title="Permalink"></a></h3><p>The arguments to Chairmarks are lowered to functions, not quoted expressions. Consequently, there is no need to interpolate variables and interpolation is therefore not supported. Like BenchmarkTools, benchmarks that includes access to nonconstant globals will receive a performance overhead for that access. However, Chairmarks evaluates expressions in the scope of the macro call, not in global scope, so nonconstant global access is much less of an issue in Chairmarks than BenchmarkTools. Three possible ways to avoid it are to put the <code>@b</code> call in a function, make the global constant, or to include it in the setup or initiaization phase. For example,</p><pre><code class="language-julia-repl hljs">julia&gt; x = 6 # nonconstant global
6

julia&gt; @b rand(x) # slow
39.616 ns (1.02 allocs: 112.630 bytes)

julia&gt; f(len) = @b rand(len)
f (generic function with 1 method)

julia&gt; f(x) # fast
19.010 ns (1 allocs: 112 bytes)

julia&gt; @b x rand # fast
18.939 ns (1 allocs: 112 bytes)

julia&gt; const X = x
6

julia&gt; @b rand(X) # fast
18.860 ns (1 allocs: 112 bytes)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../tutorial/">« Tutorial</a><a class="docs-footer-nextpage" href="../autoload/">...install Charimarks ergonomically »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.3.0 on <span class="colophon-date" title="Sunday 3 March 2024 03:43">Sunday 3 March 2024</span>. Using Julia version 1.10.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
